./bin/kbc-cli.py --train data/yago3-10/train.tsv --dev data/yago3-10/dev.tsv --test data/yago3-10/test.tsv -m complex -k 4000 -b 500 -e 100 --F2 0 --N3 0.001 -l 0.1 -I reciprocal -V 3 -o adagrad -q
{'F2': 0.0,
 'N3': 0.001,
 'batch_size': 500,
 'dev': 'data/yago3-10/dev.tsv',
 'embedding_size': 4000,
 'epochs': 100,
 'eval_batch_size': None,
 'input_type': 'reciprocal',
 'learning_rate': 0.1,
 'load': None,
 'model': 'complex',
 'optimizer': 'adagrad',
 'quiet': True,
 'save': None,
 'seed': 0,
 'test': 'data/yago3-10/test.tsv',
 'test_i': None,
 'test_ii': None,
 'train': 'data/yago3-10/train.tsv',
 'validate_every': 3}
INFO:kbc-cli.py:Device: cuda
INFO:kbc-cli.py:Model state:
INFO:kbc-cli.py:	entities.weight	torch.Size([123182, 8000])
INFO:kbc-cli.py:	predicates.weight	torch.Size([74, 8000])
Traceback (most recent call last):
  File "./bin/kbc-cli.py", line 247, in <module>
    main(sys.argv[1:])
  File "./bin/kbc-cli.py", line 209, in main
    loss.backward()
  File "/home/pminervi/anaconda3/envs/gpu/lib/python3.6/site-packages/torch/tensor.py", line 107, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/pminervi/anaconda3/envs/gpu/lib/python3.6/site-packages/torch/autograd/__init__.py", line 93, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 1.84 GiB (GPU 0; 10.92 GiB total capacity; 8.67 GiB already allocated; 1.57 GiB free; 153.53 MiB cached)
