./bin/kbc-cli.py --train data/yago3-10/train.tsv --dev data/yago3-10/dev.tsv --test data/yago3-10/test.tsv -m complex -k 2000 -b 100 -e 100 --F2 0.5 --N3 0 -l 0.1 -I reciprocal -V 3 -o adagrad -q
{'F2': 0.5,
 'N3': 0.0,
 'batch_size': 100,
 'dev': 'data/yago3-10/dev.tsv',
 'embedding_size': 2000,
 'epochs': 100,
 'eval_batch_size': None,
 'input_type': 'reciprocal',
 'learning_rate': 0.1,
 'load': None,
 'model': 'complex',
 'optimizer': 'adagrad',
 'quiet': True,
 'save': None,
 'seed': 0,
 'test': 'data/yago3-10/test.tsv',
 'test_i': None,
 'test_ii': None,
 'train': 'data/yago3-10/train.tsv',
 'validate_every': 3}
INFO:kbc-cli.py:Device: cuda
INFO:kbc-cli.py:Model state:
INFO:kbc-cli.py:	entities.weight	torch.Size([123182, 4000])
INFO:kbc-cli.py:	predicates.weight	torch.Size([74, 4000])
Traceback (most recent call last):
  File "./bin/kbc-cli.py", line 247, in <module>
    main(sys.argv[1:])
  File "./bin/kbc-cli.py", line 209, in main
    loss.backward()
  File "/home/pminervi/anaconda3/envs/gpu/lib/python3.6/site-packages/torch/tensor.py", line 107, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/pminervi/anaconda3/envs/gpu/lib/python3.6/site-packages/torch/autograd/__init__.py", line 93, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 940.00 MiB (GPU 0; 10.73 GiB total capacity; 8.47 GiB already allocated; 719.56 MiB free; 813.66 MiB cached)
