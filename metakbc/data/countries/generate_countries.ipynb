{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load and parse dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "countries.json: text/plain; charset=utf-8\n"
    }
   ],
   "source": [
    "!file countries.json -I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('countries.json', encoding='utf-8') as f:\n",
    "    raw_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "skipping Antarctica\nskipping Territory of the French Southern and Antarctic Lands\nskipping Bouvet Island\nskipping Heard Island and McDonald Islands\nskipping Macao Special Administrative Region of the People's Republic of China\nskipping United States Minor Outlying Islands\n"
    }
   ],
   "source": [
    "countries = []\n",
    "cca3_codes_to_country = dict()\n",
    "for country in raw_data:\n",
    "    name = country['name']['official']\n",
    "    cca3_codes_to_country[country['cca3']] = name\n",
    "\n",
    "for country in raw_data:\n",
    "    name = country['name']['official']\n",
    "    capital = country['capital']\n",
    "    region = country['region']\n",
    "    subregion = country['subregion']\n",
    "    neighbors = [cca3_codes_to_country[cca3_code] for cca3_code in country['borders']]\n",
    "\n",
    "    if len(name) == 0 or len(capital) == 0 or len(region) == 0 or len(subregion) == 0:\n",
    "        print(\"skipping\", name)\n",
    "        continue\n",
    "    \n",
    "    countries += [{'name': name, 'capital': capital, 'subregion': subregion, 'region': region, 'neighbors': neighbors}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = set()\n",
    "valid = set()\n",
    "test = set()\n",
    "neighbor_rule = set()\n",
    "located_in_rule = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.Random(42).shuffle(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_countries = len(countries)\n",
    "processed_countries = set()\n",
    "\n",
    "for i, country in enumerate(countries):\n",
    "    train.add((country['name'], 'located_in', country['subregion']))\n",
    "    train.add((country['subregion'], 'located_in', country['region']))\n",
    "\n",
    "    processed_countries.add(country['name'])\n",
    "\n",
    "    for neighbor in country['neighbors']:\n",
    "        if neighbor not in processed_countries:\n",
    "            train.add((country['name'], 'is_neighbor_of', neighbor))\n",
    "            valid.add((neighbor, 'is_neighbor_of', country['name']))\n",
    "            neighbor_rule.add((neighbor, 'is_neighbor_of', country['name']))\n",
    "\n",
    "    valid.add((country['name'], 'located_in', country['region']))\n",
    "    located_in_rule.add((country['name'], 'located_in', country['region']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = list(train)\n",
    "valid = list(valid)\n",
    "random.Random(42).shuffle(valid)\n",
    "valid, test = valid[:len(valid) // 2], valid[len(valid) // 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "589\n283\n283\n"
    }
   ],
   "source": [
    "print(len(train))\n",
    "print(len(valid))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check that splits are mutually exclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for triple in train:\n",
    "    if triple in valid:\n",
    "        print(\"valid\", triple)\n",
    "    if triple in test:\n",
    "        print(\"valid\", triple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for triple in valid:\n",
    "    if triple in train:\n",
    "        print(\"train\", triple)\n",
    "    if triple in test:\n",
    "        print(\"test\", triple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for triple in test:\n",
    "    if triple in train:\n",
    "        print(\"train\", triple)\n",
    "    if triple in valid:\n",
    "        print(\"valid\", triple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save splits as .tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train.tsv\", \"w\", encoding='utf-8') as f:\n",
    "    for triple in train:\n",
    "        f.write(\"{}\\t{}\\t{}\\n\".format(*triple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"valid.tsv\", \"w\", encoding='utf-8') as f:\n",
    "    for triple in valid:\n",
    "        f.write(\"{}\\t{}\\t{}\\n\".format(*triple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test.tsv\", \"w\", encoding='utf-8') as f:\n",
    "    for triple in test:\n",
    "        f.write(\"{}\\t{}\\t{}\\n\".format(*triple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"neighbor_rule.tsv\", \"w\", encoding='utf-8') as f:\n",
    "    for triple in neighbor_rule:\n",
    "        f.write(\"{}\\t{}\\t{}\\n\".format(*triple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"located_in_rule.tsv\", \"w\", encoding='utf-8') as f:\n",
    "    for triple in located_in_rule:\n",
    "        f.write(\"{}\\t{}\\t{}\\n\".format(*triple))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36864bit277cdecdadcc4196a67241552660cd03",
   "display_name": "Python 3.6.8 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}